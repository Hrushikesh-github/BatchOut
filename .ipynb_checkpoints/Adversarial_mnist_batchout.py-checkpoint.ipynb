{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important part of the implementation is done here. We check the performance of the Batchout models which are trained on the original dataset. One clarification is required. In the paper, for fgsm attacks, epsilon = 0.1 to 0.5 is done. What is the range of pixel values, from (0 to 1) or (0 to 255)? With (0, 255) the results are consistent with the paper. But with (0 to 1) my implementation is not correct because of poor robustness. \n",
    "\n",
    "I think the pixel value is not from (0 to 1). In case the pixel value was from (0 to 1) and we allow to perturb on epsilon = 0.5, then the adversarial image is very different from the original image. But with (0, 1) adversarially trained CNN has achieved what the paper describes.\n",
    "\n",
    "So the results I obtained are wrong. My implementation is not showing any difference between batchout and normally trained models. I will try with CIFAR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from architectures import *\n",
    "\n",
    "# Load the weights of our models\n",
    "\n",
    "#model_cnn.load_state_dict(torch.load(\"models/mnist_cnn.pt\", map_location=torch.device('cpu')))\n",
    "batchout_model_cnn_all.load_state_dict(torch.load(\"models/0.pt\"))\n",
    "#batchout_model_cnn_c1.load_state_dict(torch.load(\"models/1.pt\", map_location=torch.device('cpu')))\n",
    "#batchout_model_cnn_c2.load_state_dict(torch.load(\"models/2.pt\", map_location=torch.device('cpu')))\n",
    "#batchout_model_cnn_c12.load_state_dict(torch.load(\"models/3.pt\", map_location=torch.device('cpu')))\n",
    "#batchout_model_cnn_f1.load_state_dict(torch.load(\"models/4.pt\", map_location=torch.device('cpu')))\n",
    "#batchout_model_cnn_c2f1.load_state_dict(torch.load(\"models/5.pt\", map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(loader, model, opt=None):\n",
    "    \"\"\"Standard training/evaluation epoch over the dataset\"\"\"\n",
    "    total_loss, total_err = 0.,0.\n",
    "    for X,y in loader:\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        if not opt:\n",
    "            model.eval()\n",
    "            yp = model(X)\n",
    "            loss = nn.CrossEntropyLoss()(yp,y)\n",
    "        if opt:\n",
    "            model.train()\n",
    "            yp = model(X)\n",
    "            loss = nn.CrossEntropyLoss()(yp, y)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
    "        total_loss += loss.item() * X.shape[0]\n",
    "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n",
    "\n",
    "def epoch_adversarial(loader, model, attack, epsilon, opt=None, **kwargs):\n",
    "    \"\"\"Adversarial training/evaluation epoch over the dataset\"\"\"\n",
    "    total_loss, total_err = 0.,0.\n",
    "    for X,y in loader:\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        # We update our delta unlike the standard epoch and the train the model to be robust\n",
    "        delta = epsilon * attack(model, X, y)\n",
    "\n",
    "        if not opt:\n",
    "            model.eval()\n",
    "            yp = model(X + delta)\n",
    "            loss = nn.CrossEntropyLoss()(yp, y)\n",
    "\n",
    "        if opt:\n",
    "            model.train()\n",
    "            yp = model(X + delta)\n",
    "            loss = nn.CrossEntropyLoss()(yp, y)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "\n",
    "        total_err += (yp.max(dim=1)[1] != y).sum().item()\n",
    "        total_loss += loss.item() * X.shape[0]\n",
    "    return total_err / len(loader.dataset), total_loss / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm(model, X, y):\n",
    "    \"\"\" Construct FGSM adversarial examples on the examples X\"\"\"\n",
    "    delta = torch.zeros_like(X, requires_grad=True)\n",
    "    loss = nn.CrossEntropyLoss()(model(X + delta), y)\n",
    "    loss.backward()\n",
    "    return delta.grad.detach().sign() # We will multiply epsilon in the epoch functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.MNIST(\"./data\", train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size = 1000, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size = 1000, shuffle=False)\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we would like to know both the test error and the adversarial error, this cell can be run\n",
    "models = [batchout_model_cnn_all, batchout_model_cnn_c1, batchout_model_cnn_c2, batchout_model_cnn_c12, batchout_model_cnn_f1, batchout_model_cnn_c2f1]\n",
    "e = 0.1\n",
    "for i, model in enumerate(models):\n",
    "    test_err, test_loss = epoch(test_loader, model)\n",
    "    adv_err, adv_loss = epoch_adversarial(test_loader, model, fgsm, e)\n",
    "    print('Model: {}, test error is {} adversaries_error for epsilon=0.1 is {}: '.format(i + 1, test_err, adv_err))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchOut()\n",
      "  (2): ReLU()\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "  (5): BatchOut()\n",
      "  (6): ReLU()\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): Flatten()\n",
      "  (9): Dropout(p=0.5, inplace=False)\n",
      "  (10): Linear(in_features=800, out_features=256, bias=True)\n",
      "  (11): BatchOut()\n",
      "  (12): ReLU()\n",
      "  (13): Dropout(p=0.5, inplace=False)\n",
      "  (14): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Model: 1, error against adversaries for epsilon 0.1 is: \t0.321000\n",
      "Model: 1, error against adversaries for epsilon 0.2 is: \t0.816500\n",
      "Model: 1, error against adversaries for epsilon 0.3 is: \t0.990900\n",
      "Model: 1, error against adversaries for epsilon 0.4 is: \t0.998100\n",
      "Model: 1, error against adversaries for epsilon 0.5 is: \t0.997400\n"
     ]
    }
   ],
   "source": [
    "# We are just checking accuracy against the adversarial attacks on of the batchout models. No Training\n",
    "models = [batchout_model_cnn_all]\n",
    "epsilons = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    print(model)\n",
    "    for e in epsilons: \n",
    "\n",
    "        adv_err, adv_loss = epoch_adversarial(test_loader, model, fgsm, e)\n",
    "        print('Model: {}, error against adversaries for epsilon {} is: '.format(i + 1, e), \"{:.6f}\".format(adv_err), sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9690000414848328\n",
      "For epsilon 0.00392156862745098 probability obtained is 0.962\n",
      "For epsilon 0.00784313725490196 probability obtained is 0.956\n",
      "For epsilon 0.011764705882352941 probability obtained is 0.958\n",
      "For epsilon 0.01568627450980392 probability obtained is 0.954\n",
      "For epsilon 0.0196078431372549 probability obtained is 0.943\n",
      "For epsilon 0.1 probability obtained is 0.776\n",
      "For epsilon 0.2 probability obtained is 0.321\n",
      "For epsilon 0.3 probability obtained is 0.015\n",
      "For epsilon 0.4 probability obtained is 0.001\n",
      "For epsilon 0.5 probability obtained is 0.001\n"
     ]
    }
   ],
   "source": [
    "# Perform the attack using Foolbox and check the accuracy\n",
    "device = 'cuda'\n",
    "X,y = next(iter(test_loader))\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "import foolbox as fb\n",
    "\n",
    "fmodel = fb.PyTorchModel(batchout_model_cnn_all, bounds=(0, 1))\n",
    "\n",
    "print(fb.utils.accuracy(fmodel, X, y))\n",
    "attack = fb.attacks.FGSM()\n",
    "\n",
    "for e in [1/255, 2/255, 3/255, 4/255, 5/255, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    \n",
    "    (raw, clipped, is_adv) = attack(fmodel, X, y, epsilons=e)\n",
    "\n",
    "    total_err = (is_adv != True).sum().item() / 1000\n",
    "\n",
    "    print('For epsilon {} probability obtained is {}'.format(e, total_err))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004\n"
     ]
    }
   ],
   "source": [
    "attack = fb.attacks.LinfDeepFoolAttack()\n",
    "    \n",
    "(raw, clipped, is_adv) = attack(fmodel, X, y, epsilons=e)\n",
    "\n",
    "total_err = (is_adv != True).sum().item() / 1000\n",
    "\n",
    "print(total_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. (DONE) Check the accuracy of the all connected batchout model on adversarial samples (In this file)\n",
    "# 2. (DONE) Check the accuracy of normally trained network against adversaries (In this file)\n",
    "# 3. (DONE) Create a adversarially trained model with the same architecture (excluding batchout though) (In another file)\n",
    "# 4. The above tasks must be done for different epsilon values of [0.1, 0.2, 0.3, 0.4, 0.5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
